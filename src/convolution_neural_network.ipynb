{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitf498ff391bd141efa82a8b19ebf9c273",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution is to find something useful, and pooling is to bring it together\n",
    "#think divide and conquer\n",
    "\n",
    "#for images, convolution might be taking a samller window of the image, and simplfy what it finds in the window, and then shift it\n",
    "#this should extract features from the image\n",
    "\n",
    "#pixels -> edges -> lines -> shapes -> features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 22451 samples, validate on 2495 samples\nEpoch 1/10\n22451/22451 [==============================] - 69s 3ms/sample - loss: 0.6589 - accuracy: 0.6034 - val_loss: 0.6008 - val_accuracy: 0.6826\nEpoch 2/10\n22451/22451 [==============================] - 78s 3ms/sample - loss: 0.5673 - accuracy: 0.7089 - val_loss: 0.5471 - val_accuracy: 0.7375\nEpoch 3/10\n22451/22451 [==============================] - 87s 4ms/sample - loss: 0.5038 - accuracy: 0.7548 - val_loss: 0.4688 - val_accuracy: 0.7804\nEpoch 4/10\n22451/22451 [==============================] - 87s 4ms/sample - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4649 - val_accuracy: 0.7868\nEpoch 5/10\n22451/22451 [==============================] - 87s 4ms/sample - loss: 0.4387 - accuracy: 0.7976 - val_loss: 0.4471 - val_accuracy: 0.7944\nEpoch 6/10\n22451/22451 [==============================] - 206s 9ms/sample - loss: 0.4139 - accuracy: 0.8103 - val_loss: 0.4382 - val_accuracy: 0.8072\nEpoch 7/10\n22451/22451 [==============================] - 87s 4ms/sample - loss: 0.3920 - accuracy: 0.8215 - val_loss: 0.4420 - val_accuracy: 0.7920\nEpoch 8/10\n22451/22451 [==============================] - 87s 4ms/sample - loss: 0.3692 - accuracy: 0.8350 - val_loss: 0.4535 - val_accuracy: 0.7904\nEpoch 9/10\n22451/22451 [==============================] - 86s 4ms/sample - loss: 0.3481 - accuracy: 0.8476 - val_loss: 0.4477 - val_accuracy: 0.8056\nEpoch 10/10\n22451/22451 [==============================] - 89s 4ms/sample - loss: 0.3361 - accuracy: 0.8514 - val_loss: 0.4716 - val_accuracy: 0.7872\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x294dbaa8f98>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation,Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "#normalize the data\n",
    "X = X/255.0\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "model.fit(X, y, batch_size=32, epochs = 10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}