{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution is to find something useful, and pooling is to bring it together\n",
    "#think divide and conquer\n",
    "\n",
    "#for images, convolution might be taking a samller window of the image, and simplfy what it finds in the window, and then shift it\n",
    "#this should extract features from the image\n",
    "\n",
    "#pixels -> edges -> lines -> shapes -> features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 1s 566us/sample - loss: 0.0156 - accuracy: 0.9977 - val_loss: 1.5404e-06 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 2s 895us/sample - loss: 0.0243 - accuracy: 0.9897 - val_loss: 3.0163e-08 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 3s 1ms/sample - loss: 0.0589 - accuracy: 0.9878 - val_loss: 3.8200e-09 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 2s 858us/sample - loss: 0.0123 - accuracy: 0.9992 - val_loss: 1.7028e-07 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 4s 1ms/sample - loss: 0.0226 - accuracy: 0.9886 - val_loss: 1.8667e-12 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 4s 2ms/sample - loss: 0.0350 - accuracy: 0.9890 - val_loss: 2.7976e-16 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 4s 1ms/sample - loss: 0.0110 - accuracy: 0.9970 - val_loss: 5.2635e-09 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 8s 3ms/sample - loss: 0.0152 - accuracy: 0.9996 - val_loss: 1.2970e-17 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 9s 3ms/sample - loss: 0.0180 - accuracy: 0.9882 - val_loss: 5.4184e-29 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 2s 612us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 9.0857e-10 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 2s 916us/sample - loss: 0.0146 - accuracy: 0.9890 - val_loss: 1.2865e-10 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 3s 1ms/sample - loss: 0.0327 - accuracy: 0.9992 - val_loss: 3.1024e-13 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 3s 1ms/sample - loss: 0.0093 - accuracy: 0.9878 - val_loss: 1.2184e-11 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 4s 2ms/sample - loss: 0.0140 - accuracy: 0.9878 - val_loss: 5.3554e-17 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 4s 2ms/sample - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.1722e-25 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 6s 2ms/sample - loss: 0.0087 - accuracy: 0.9878 - val_loss: 1.2039e-16 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 8s 3ms/sample - loss: 0.0118 - accuracy: 0.9878 - val_loss: 6.5992e-28 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 9s 3ms/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 2s 687us/sample - loss: 0.0107 - accuracy: 0.9886 - val_loss: 2.2549e-08 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 2s 935us/sample - loss: 0.0238 - accuracy: 0.9954 - val_loss: 5.8735e-12 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 3s 1ms/sample - loss: 0.0556 - accuracy: 0.9905 - val_loss: 3.4935e-12 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 3s 1ms/sample - loss: 0.0096 - accuracy: 0.9878 - val_loss: 2.4380e-11 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 4s 2ms/sample - loss: 0.0354 - accuracy: 0.9878 - val_loss: 5.4739e-16 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 5s 2ms/sample - loss: 0.0297 - accuracy: 0.9893 - val_loss: 1.5320e-28 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 6s 2ms/sample - loss: 0.0088 - accuracy: 0.9890 - val_loss: 2.5783e-17 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 9s 3ms/sample - loss: 0.0154 - accuracy: 0.9878 - val_loss: 1.3807e-37 - val_accuracy: 1.0000\nTrain on 2625 samples, validate on 292 samples\n2625/2625 [==============================] - 9s 3ms/sample - loss: 0.0194 - accuracy: 0.9985 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation,Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "NAME = \"Cats-vs-Dogs-CNN\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs\\\\%s' %NAME)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "#normalize the data\n",
    "X = X/255.0\n",
    "\n",
    "#Add input layer\n",
    "\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [32,64,128]\n",
    "conv_layers = [1,2,3]\n",
    "\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer,layer_size,dense_layer,int(time.time()))\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape = X.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            for l in range(conv_layer-1):\n",
    "                #Deep layers\n",
    "                model.add(Conv2D(layer_size,(3,3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "            model.add(Flatten()) #convert out 3D feature maps to 1D feature vectures\n",
    "          \n",
    "            for l in range(dense_layer):\n",
    "              model.add(Dense(layer_size))\n",
    "              model.add(Activation(\"relu\"))\n",
    "\n",
    "            #output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "            model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "            X = np.asarray(X)\n",
    "            y = np.asarray(y)\n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs = 1, validation_split=0.1,callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bit9b3e7e6d21bc4b2590da42f717a6f136",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}